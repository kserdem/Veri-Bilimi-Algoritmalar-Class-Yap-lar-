{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS YAPILARI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series , DataFrame\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "dataFrame=pd.read_csv(' ')\n",
    "\n",
    "data=dataFrame.copy()\n",
    "data.head()\n",
    "y=data['target variable']\n",
    "X=data.drop([''],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İNFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series , DataFrame\n",
    "dataFrame=pd.read_csv('Titanic.csv')\n",
    "data=dataFrame.copy()\n",
    "\n",
    "class info:\n",
    "   \n",
    "    def __init__(self,data):\n",
    "        \n",
    "        print(data.head())\n",
    "        return data.info()\n",
    "    def describe(self,data):\n",
    "        return data.describe()\n",
    "\n",
    "    def null(self,data):#çalışmıyor bak\n",
    "        print(data.isnull().sum())\n",
    "    def drop(self,data):\n",
    "        print(data.dropna().isnull().sum())\n",
    "    def categorize(self,data):\n",
    "        kat_df = data.select_dtypes(include = [\"object\"])#type object olan değişkenleri bulur\n",
    "        print(kat_df.head())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Visualization:\n",
    "   \n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def scatplot(self, data1, data2, xlabel=None, ylabel=None):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.scatter(data1, data2)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.show()\n",
    "\n",
    "    def histogram(self, data):\n",
    "        sns.distplot(data)\n",
    "        plt.show()      \n",
    "    def boxplot(self,data):\n",
    "        sns.boxplot(x=data)\n",
    "    def pairplot(self,data):\n",
    "        sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series , DataFrame\n",
    "class Variable:\n",
    "   \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    \n",
    "        \n",
    "    def getdummy(self,data):\n",
    "         dms=pd.get_dummies(data)\n",
    "         \n",
    "         print(dms.head())\n",
    "         X_=data.drop(data, axis=1)\n",
    "         print(X_.head())\n",
    "         data=pd.concat([X_,dms],axis=1)\n",
    "        \n",
    "    def target(self,data):\n",
    "        y=data(data)\n",
    "        X_=data.drop(data,axis=1)\n",
    "        print(X.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class PCAnalize:\n",
    "    \n",
    "   \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def standart(self,data):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X) \n",
    "        \n",
    "    def  pcamodel(self,data):\n",
    "        \n",
    "        pca=PCA()\n",
    "        pca.fit_transform(X_train)\n",
    "        a=np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)[0:15]\n",
    "        print('değişkenlerin kümülatif açıklanma oranları', a)\n",
    "    \n",
    "        features = range(pca.n_components_)\n",
    "        plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "        plt.xlabel('PCA features')\n",
    "        plt.ylabel('variance %')\n",
    "        plt.xticks(features)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "class LinearRegression:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def statsmodel(self,data):\n",
    "        lm = sm.OLS(y,X)\n",
    "        model = lm.fit()\n",
    "        print(model.summary())\n",
    "    def olsmodel(self,data):\n",
    "        import statsmodels.formula.api as smf\n",
    "        lm = smf.ols(\"y ~ X\", data)\n",
    "        model = lm.fit()\n",
    "        print(model.summary())\n",
    "    def linearFit(self,data):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        reg = LinearRegression()\n",
    "        model = reg.fit(X, y)\n",
    "        print('model intercept: ',model.intercept_)\n",
    "        print('model coef: ',model.coef_)\n",
    "        print('model score:',model.score(X,y))\n",
    "        print('ilk 10 değişken için model predict: ',model.predict(X)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "   \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def CartRegressor(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        cart_model = DecisionTreeRegressor()\n",
    "        cart_model.fit(X_train, y_train)\n",
    "        y_pred =cart_model.predict(X_test)\n",
    "        sqrt= np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(\"Cart Regressor Model Squared Error: \",sqrt)\n",
    "        \n",
    "    def CartRegressorTuned(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        cart_model = DecisionTreeRegressor()\n",
    "        \n",
    "        \n",
    "        cart_params = {\"max_leaf_nodes\": range(4,8),\n",
    "                       \"min_samples_leaf\": [10,15,20],\n",
    "                       \"min_samples_split\": range(10,50) }\n",
    "        \n",
    "        cart_cv_model = GridSearchCV(cart_model, cart_params, cv = 10)\n",
    "        cart_cv_model.fit(X_train, y_train)\n",
    "        print(\"model için best parametreler :\" ,cart_cv_model.best_params_)\n",
    "        params=cart_cv_model.best_params_\n",
    "        cart_tuned = DecisionTreeRegressor(min_samples_split=params['min_samples_split'],\n",
    "                                           min_samples_leaf=params['min_samples_leaf'],\n",
    "                                           max_leaf_nodes=params['max_leaf_nodes'])\n",
    "        cart_tuned.fit(X_train, y_train)\n",
    "        y_pred =cart_tuned.predict(X_test)\n",
    "        sqrt2= np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(\"Cart Regressor Model Squared Error: \",sqrt2)\n",
    "        \n",
    "        \n",
    "    def CartClassifier(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        cart_model = DecisionTreeClassifier()\n",
    "        cart_model.fit(X_train, y_train)\n",
    "        y_pred =cart_model.predict(X_test)\n",
    "        sqrt= np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(\"Cart Classifier Model Squared Error: \",sqrt)\n",
    "        print(\"Cart Classifier Model Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "              \n",
    "    def CartClassifierTuned(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        cart_model = DecisionTreeClassifier()\n",
    "        \n",
    "        \n",
    "        cart_grid = {\"max_depth\": range(1,10),\n",
    "            \"min_samples_split\" : list(range(2,50)) }\n",
    "        \n",
    "        cart_cv_model = GridSearchCV(cart_model, cart_grid, cv = 10, n_jobs = -1, verbose = 2)\n",
    "        cart_cv_model.fit(X_train, y_train)\n",
    "        print(\"model için best parametreler :\" ,cart_cv_model.best_params_)\n",
    "        params=cart_cv_model.best_params_\n",
    "        cart_tuned = DecisionTreeClassifier(min_samples_split=params['min_samples_split'],\n",
    "                                           min_samples_leaf=params['max_depth'])\n",
    "                                          \n",
    "        cart_tuned.fit(X_train, y_train)\n",
    "        y_pred =cart_tuned.predict(X_test)\n",
    "        sqrt2= np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(\"Cart Regressor Model Squared Error: \",sqrt2)\n",
    "        print(\"Cart Classifier Model Tuned Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        \n",
    "    def RandomForestRegressor(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(\"Random Forest Regressor Model MSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        Importance = pd.DataFrame({\"Importance\": rf_model.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")\n",
    "        \n",
    "    def RandomForestRegressorTuned(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_params = {'max_depth': list(range(1,10)),\n",
    "            'max_features': [3,5,10,15],\n",
    "            'n_estimators' : [100, 200, 500, 1000, 2000]}\n",
    "        rf_cv_model = GridSearchCV(rf_model, \n",
    "                           rf_params, \n",
    "                           cv=10, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2)\n",
    "        rf_cv_model.fit(X_train, y_train)\n",
    "        params= rf_cv_model.best_params_\n",
    "        rf_tuned = RandomForestRegressor(max_depth  = params['max_depth'], \n",
    "                                 max_features = params['max_features'], \n",
    "                                 n_estimators = params['n_estimators'])\n",
    "        rf_tuned.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(\"Random Forest Regressor Model Tuned MSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")\n",
    "        \n",
    "        \n",
    "    def RandomForestClassifier(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        rf_model = RandomForestClassifier(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(\"Random Forest Classifier Model MSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"Random Forest Classifier Model  Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        Importance = pd.DataFrame({\"Importance\": rf_model.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")\n",
    "        \n",
    "    def RandomForestClassifierTuned(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        rf_model = RandomForestClassifier(random_state = 42)\n",
    "        rf_params = {'max_depth': list(range(1,10)),\n",
    "            'max_features': [3,5,10,15],\n",
    "            'n_estimators' : [100, 200, 500, 1000, 2000]}\n",
    "        rf_cv_model = GridSearchCV(rf_model, \n",
    "                           rf_params, \n",
    "                           cv=10, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2)\n",
    "        rf_cv_model.fit(X_train, y_train)\n",
    "        params= rf_cv_model.best_params_\n",
    "        rf_tuned = RandomForestClassifier(max_depth  = params['max_depth'], \n",
    "                                 max_features = params['max_features'], \n",
    "                                 n_estimators = params['n_estimators'])\n",
    "        rf_tuned.fit(X_train, y_train)\n",
    "        y_pred = rf_tuned.predict(X_test)\n",
    "        print(\"Random Forest Classifier Model Tuned MSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"Random Forest Classifier Model  Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def NeuralRegressor(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        \n",
    "        mlp_model = MLPRegressor(hidden_layer_sizes = (100,20)).fit(X_train, y_train)\n",
    "        y_pred = mlp_model.predict(X_test)\n",
    "        print(\"Neural Network Regressor Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def NeuralRegressorTuned(self,data):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        mlp_model = MLPRegressor(hidden_layer_sizes = (100,20))\n",
    "        mlp_params = {'alpha': [0.1, 0.01,0.02,0.005],\n",
    "             'hidden_layer_sizes': [(20,20),(100,50,150),(300,200,150)],\n",
    "             'activation': ['relu','logistic']}\n",
    "        \n",
    "        mlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv = 10)\n",
    "        mlp_cv_model.fit(X_train, y_train)\n",
    "        params=mlp_cv_model.best_params_\n",
    "        mlp_tuned = MLPRegressor(alpha = params['alpha'], \n",
    "                                 hidden_layer_sizes =params['hidden_layer_sizes'],\n",
    "                                 activation=params['activation'])\n",
    "        mlp_tuned.fit(X_train, y_train)\n",
    "        y_pred = mlp_tuned.predict(X_test)\n",
    "        print(\"Neural Network Regressor Modeli Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def NeuralClassifier(self,data):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        \n",
    "        mlp_model = MLPClassifier(hidden_layer_sizes = (100,20)).fit(X_train, y_train)\n",
    "        y_pred = mlp_model.predict(X_test)\n",
    "        print(\"Neural Network Classifier Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"Neural Network Classifier Model  Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def NeuralClassifierTuned(self,data):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.neural_network import MLPClassifier\n",
             
    "        mlp_model = MLPClassifier(hidden_layer_sizes = (100,20))\n",
    "        mlpc_params = {\"alpha\": [0.1, 0.01, 0.02, 0.005],\n",
    "              \"hidden_layer_sizes\": [(10,10,10),\n",
    "                                     (100,100,100),\n",
    "                                     (100,100),\n",
    "                                     (3,5), \n",
    "                                     (5, 3)],\n",
    "              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n",
    "              \"activation\": [\"relu\",\"logistic\"]}\n",
    "\n",
    "        \n",
    "        mlp_cv_model = GridSearchCV(mlp_model, mlpc_params, cv = 10)\n",
    "        mlp_cv_model.fit(X_train, y_train)\n",
    "        params=mlp_cv_model.best_params_\n",
    "        mlp_tuned = MLPClassifier(alpha = params['alpha'], \n",
    "                                 hidden_layer_sizes =params['hidden_layer_sizes'],\n",
    "                                 activation=params['activation'],\n",
    "                                 solver=params['solver']).fit(X_train, y_train)\n",
    "        y_pred = mlp_tuned.predict(X_test)\n",
    "        print(\"Neural Network Classifier Modeli Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"Neural Network Classifier Model  Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAİVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def NaiveModel(self,data):\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        nb = GaussianNB()\n",
    "        nb_model = nb.fit(X_train, y_train)\n",
    "        nb_model\n",
    "        y_pred = nb_model.predict(X_test)\n",
    "        print(\"Naive Bayes Modeli Accuracy Score:\",accuracy_score(y_test, y_pred))\n",
    "        print(\"Cross Validation Score Mean:\",cross_val_score(nb_model, X_test, y_test, cv = 10).mean())\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBM:\n",
    "   \n",
    "    def __init__(self,data):\n",
    "        self.data=self\n",
    "    \n",
    "        \n",
    "    def GBMRegressorModel(self,data):\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        gbm_model = GradientBoostingRegressor()\n",
    "        gbm_model.fit(X_train, y_train)\n",
    "        y_pred = gbm_model.predict(X_test)\n",
    "        print(\"GBM Regressor Model MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    def GBMRegressorModelTuned(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        gbm_params = { 'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 8,50,100],\n",
    "            'n_estimators': [200, 500, 1000, 2000],\n",
    "            'subsample': [1,0.5,0.75],}\n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm_cv_model = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)\n",
    "        gbm_cv_model.fit(X_train, y_train)\n",
    "        params=gbm_cv_model.best_params_\n",
    "        gbm_tuned = GradientBoostingRegressor(learning_rate = params['learning_rate'],  \n",
    "                                      max_depth =['max_depth'] , \n",
    "                                      n_estimators =['n_estimators'] , \n",
    "                                      subsample = ['subsample'])\n",
    "\n",
    "        gbm_tuned = gbm_tuned.fit(X_train,y_train)\n",
    "        y_pred = gbm_tuned.predict(X_test)\n",
    "        print(\"GBM Regressor Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "   \n",
    "        Importance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")\n",
    "\n",
    "        \n",
    "    def GBMClassifierModel(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        gbm_model = GradientBoostingClassifier()\n",
    "        gbm_model.fit(X_train, y_train)\n",
    "        y_pred = gbm_model.predict(X_test)\n",
    "        print(\"GBM Classifier Model MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    def GBMClassifierModelTuned(self,data):\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        gbm_params = { 'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 8,50,100],\n",
    "            'n_estimators': [200, 500, 1000, 2000],\n",
    "            'subsample': [1,0.5,0.75],}\n",
    "        gbm = GradientBoostingClassifier()\n",
    "        gbm_cv_model = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)\n",
    "        gbm_cv_model.fit(X_train, y_train)\n",
    "        params=gbm_cv_model.best_params_\n",
    "        gbm_tuned = GradientBoostingClassifier(learning_rate = params['learning_rate'],  \n",
    "                                      max_depth =['max_depth'] , \n",
    "                                      n_estimators =['n_estimators'] , \n",
    "                                      subsample = ['subsample'])\n",
    "\n",
    "        gbm_tuned = gbm_tuned.fit(X_train,y_train)\n",
    "        y_pred = gbm_tuned.predict(X_test)\n",
    "        print(\"GBM Regressor Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "   \n",
    "        Importance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "class XGBOOST:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def XGBoostRegressorModel(self,data):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from xgboost import XGBRegressor\n",
    "        import xgboost as xgb\n",
    "        xgb_model = XGBRegressor().fit(X_train, y_train)\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        print(\"XGBoost Regressor Model MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    def XGBoostRegressorModelTuned(self,data):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from xgboost import XGBRegressor\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        xgb_grid = {'colsample_bytree': [0.4, 0.5,0.6,0.9,1], \n",
    "                     'n_estimators':[100, 200, 500, 1000],\n",
    "                     'max_depth': [2,3,4,5,6],\n",
    "                     'learning_rate': [0.1, 0.01, 0.5]}\n",
    "        xgb = XGBRegressor()\n",
    "\n",
    "        xgb_cv = GridSearchCV(xgb, \n",
    "                      param_grid = xgb_grid, \n",
    "                      cv = 10, \n",
    "                      n_jobs = -1,\n",
    "                      verbose = 2)\n",
    "\n",
    "\n",
    "        xgb_cv.fit(X_train, y_train)\n",
    "        params=xgb_cv.best_params_\n",
    "        xgb_tuned = XGBRegressor(colsample_bytree =params['colsample_bytree'], \n",
    "                         learning_rate =params['learning_rate'], \n",
    "                         max_depth = params['max_depth'], \n",
    "                         n_estimators = params['n_estimators']) \n",
    "\n",
    "        xgb_tuned = xgb_tuned.fit(X_train,y_train)\n",
    "        y_pred = xgb_tuned.predict(X_test)\n",
    "        print(\"XGBoost Regressor Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def XGBoostClassifierModel(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from xgboost import XGBClassifier\n",
    "        import xgboost as xgb\n",
    "        xgb_model = XGBClassifier().fit(X_train, y_train)\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        print(\"XGBoost Classifier Model MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    def XGBoostClassifierModelTuned(self,data):\n",
    "        from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "        from xgboost import XGBClassifier\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        xgb_grid = {'colsample_bytree': [0.4, 0.5,0.6,0.9,1], \n",
    "                     'n_estimators':[100, 200, 500, 1000],\n",
    "                     'max_depth': [2,3,4,5,6],\n",
    "                     'learning_rate': [0.1, 0.01, 0.5]}\n",
    "        xgb = XGBClassifier()\n",
    "\n",
    "        xgb_cv = GridSearchCV(xgb, \n",
    "                      param_grid = xgb_grid, \n",
    "                      cv = 10, \n",
    "                      n_jobs = -1,\n",
    "                      verbose = 2)\n",
    "\n",
    "\n",
    "        xgb_cv.fit(X_train, y_train)\n",
    "        params=xgb_cv.best_params_\n",
    "        xgb_tuned = XGBClassifier(colsample_bytree =params['colsample_bytree'], \n",
    "                         learning_rate =params['learning_rate'], \n",
    "                         max_depth = params['max_depth'], \n",
    "                         n_estimators = params['n_estimators']) \n",
    "\n",
    "        xgb_tuned = xgb_tuned.fit(X_train,y_train)\n",
    "        y_pred = xgb_tuned.predict(X_test)\n",
    "        print(\"XGBoost Classifier Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "#!conda install -c conda-forge lightgbm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "class LightGBM:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def LGBMRegressorModel(self,data):\n",
    "        lgbm = LGBMRegressor()\n",
    "        lgbm_model = lgbm.fit(X_train, y_train)\n",
    "        y_pred = lgbm_model.predict(X_test, \n",
    "                            num_iteration = lgbm_model.best_iteration_)\n",
    "        print(\"LightGBM Regressor Model  MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    def LGBMRegressorModelTuned(self,data):\n",
    "        lgbm_grid = {'colsample_bytree': [0.4, 0.5,0.6],\n",
    "                    'learning_rate': [0.01, 0.1, 0.5,1],\n",
    "                    'n_estimators': [ 100, 200, 500],\n",
    "                    'max_depth': [6,7,8] }\n",
    "        lgbm = LGBMRegressor()\n",
    "        lgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs = -1, verbose = 2)\n",
    "        lgbm_cv_model.fit(X_train,y_train)\n",
    "        params=lgbm_cv_model.best_params_\n",
    "        lgbm_tuned = LGBMRegressor(learning_rate = params['learning_rate'],\n",
    "                           max_depth = params['max_depth'], \n",
    "                           n_estimators = params['n_estimators'],\n",
    "                          colsample_bytree = params['colsample_bytree'])\n",
    "\n",
    "        lgbm_tuned = lgbm_tuned.fit(X_train,y_train)\n",
    "        y_pred = lgbm_tuned.predict(X_test)\n",
    "        print(\"LightGBM Regressor Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        def LGBMClassifierModel(self,data):\n",
    "            lgbm_model = LGBMClassifier().fit(X_train, y_train)\n",
    "            y_pred = lgbm_model.predict(X_test)\n",
    "            print(\"LightGBM Regressor Modeli Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        def LGBMClassifierModelTuned(self,data):\n",
    "            lgbm_grid = {'colsample_bytree': [0.4, 0.5,0.6],\n",
    "                        'learning_rate': [0.01, 0.1, 0.5,1],\n",
    "                        'n_estimators': [ 100, 200, 500],\n",
    "                        'max_depth': [6,7,8] }\n",
    "            lgbm = LGBMClassifier()\n",
    "            lgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs = -1, verbose = 2)\n",
    "            lgbm_cv_model.fit(X_train,y_train)\n",
    "            params=lgbm_cv_model.best_params_\n",
    "            lgbm_tuned = LGBMClassifier(learning_rate = params['learning_rate'],\n",
    "                           max_depth = params['max_depth'], \n",
    "                           n_estimators = params['n_estimators'],\n",
    "                          colsample_bytree = params['colsample_bytree'])\n",
    "\n",
    "            lgbm_tuned = lgbm_tuned.fit(X_train,y_train)\n",
    "            y_pred = lgbm_tuned.predict(X_test)\n",
    "            print(\"LightGBM Classifier Model Tuned MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "class CatBoost:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def CatBoostRegressor(self,data):\n",
    "        catb = CatBoostRegressor()\n",
    "        catb_model = catb.fit(X_train, y_train)\n",
    "        y_pred = catb_model.predict(X_test)\n",
    "        print(\"CatBoost Regressor Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def CatBoostRegressorTuned(self,data):\n",
    "        catb_grid = {\n",
    "            'iterations': [200,500,1000],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "            'depth': [3,4,5,6,7,8] }\n",
    "        catb = CatBoostRegressor()\n",
    "        catb_cv_model = GridSearchCV(catb, catb_grid, cv=5, n_jobs = -1, verbose = 2)\n",
    "        catb_cv_model.fit(X_train, y_train)\n",
    "        params=catb_cv_model.best_params_\n",
    "        catb_tuned = CatBoostRegressor(iterations = params['iterations'], \n",
    "                               learning_rate = params['learning_rate'], \n",
    "                               depth = ['depth'])\n",
    "\n",
    "        catb_tuned = catb_tuned.fit(X_train,y_train)\n",
    "        y_pred = catb_tuned.predict(X_test)\n",
    "        print(\"CatBoost Regressor Tuned Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def CatBoostClassifier(self,data):\n",
    "        catb = CatBoostClassifier()\n",
    "        catb_model = catb.fit(X_train, y_train)\n",
    "        y_pred = catb_model.predict(X_test)\n",
    "        print(\"CatBoost Classifier Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def CatBoostClassifierTuned(self,data):\n",
    "        catb_grid = {\n",
    "            'iterations': [200,500,1000],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "            'depth': [3,4,5,6,7,8] }\n",
    "        catb = CatBoostClassifier()\n",
    "        catb_cv_model = GridSearchCV(catb, catb_grid, cv=5, n_jobs = -1, verbose = 2)\n",
    "        catb_cv_model.fit(X_train, y_train)\n",
    "        params=catb_cv_model.best_params_\n",
    "        catb_tuned = CatBoostClassifier(iterations = params['iterations'], \n",
    "                               learning_rate = params['learning_rate'], \n",
    "                               depth = ['depth'])\n",
    "\n",
    "        catb_tuned = catb_tuned.fit(X_train,y_train)\n",
    "        y_pred = catb_tuned.predict(X_test)\n",
    "        print(\"CatBoost Classifier Tuned Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "class KNN:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def KNNRegressor(self,data):\n",
    "        knn_model = KNeighborsRegressor().fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(\"KNN Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        RMSE = [] \n",
    "\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            RMSE.append(rmse) \n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse)\n",
    "    def KNNRegressorTuned(self,data):\n",
    "        knn_params = {'n_neighbors': np.arange(1,30,1)}\n",
    "        knn = KNeighborsRegressor()\n",
    "        knn_cv_model = GridSearchCV(knn, knn_params, cv = 10)\n",
    "        knn_cv_model.fit(X_train, y_train)\n",
    "        knn_cv_model.best_params_[\"n_neighbors\"]\n",
    "        RMSE = [] \n",
    "        RMSE_CV = []\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n",
    "                                         scoring = \"neg_mean_squared_error\").mean())\n",
    "            RMSE.append(rmse) \n",
    "            RMSE_CV.append(rmse_cv)\n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse, \"RMSE_CV değeri: \", rmse_cv )\n",
    "        knn_tuned = KNeighborsRegressor(n_neighbors = knn_cv_model.best_params_[\"n_neighbors\"])\n",
    "        knn_tuned.fit(X_train, y_train)\n",
    "        print(\"KNN Modeli Tuned MSE: \",np.sqrt(mean_squared_error(y_test, knn_tuned.predict(X_test))))\n",
    "        \n",
    "        \n",
    "    def KNNClassifier(self,data):\n",
    "        knn_model = KNeighborsClassifier().fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(\"KNN Classifier Modeli MSE: \",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "       \n",
    "    def KNNClassifierTuned(self,data):\n",
    "        knn_params = {'n_neighbors': np.arange(1,30,1)}\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn_cv_model = GridSearchCV(knn, knn_params, cv = 10)\n",
    "        knn_cv_model.fit(X_train, y_train)\n",
    "        knn_cv_model.best_params_[\"n_neighbors\"]\n",
    "        RMSE = [] \n",
    "        RMSE_CV = []\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n",
    "                                         scoring = \"neg_mean_squared_error\").mean())\n",
    "            RMSE.append(rmse) \n",
    "            RMSE_CV.append(rmse_cv)\n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse, \"RMSE_CV değeri: \", rmse_cv )\n",
    "        knn_tuned = KNeighborsClassifier(n_neighbors = knn_cv_model.best_params_[\"n_neighbors\"])\n",
    "        knn_tuned.fit(X_train, y_train)\n",
    "        print(\"KNN Classifier Modeli Tuned MSE: \",np.sqrt(mean_squared_error(y_test, knn_tuned.predict(X_test))))\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade matplotlib\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import mpl_toolkits\n",
    "#!pip install yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "class KMEANS:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def KMeansModel(self,data):\n",
    "        data.hist(figsize = (10,10));\n",
    "        kmeans = KMeans(n_clusters = 4)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        print(\"Clusters: \",k_fit.n_clusters)\n",
    "        print(\"Clusters Centers: \",k_fit.cluster_centers_)\n",
    "        print(\"Labels: \",k_fit.labels_)\n",
    "        kmeans = KMeans(n_clusters = 2)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        kumeler = k_fit.labels_\n",
    "        plt.scatter(df.iloc[:,0], df.iloc[:,1], c = kumeler, s = 50, cmap = \"viridis\")\n",
    "\n",
    "        merkezler = k_fit.cluster_centers_\n",
    "\n",
    "        plt.scatter(merkezler[:,0], merkezler[:,1], c = \"black\", s = 200, alpha = 0.5);kmeans = KMeans(n_clusters = 3)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        kumeler = k_fit.labels_\n",
    "        merkezler = kmeans.cluster_centers_\n",
    "        kmeans = KMeans(n_clusters = 3)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        kumeler = k_fit.labels_\n",
    "        merkezler = kmeans.cluster_centers_\n",
    "        plt.rcParams['figure.figsize'] = (16, 9)\n",
    "        fig = plt.figure()\n",
    "        ax = Axes3D(fig)\n",
    "        ax.scatter(df.iloc[:, 0], df.iloc[:, 1], df.iloc[:, 2]);\n",
    "    def OptimumKume (self,data):\n",
    "        kmeans = KMeans()\n",
    "        visualizer = KElbowVisualizer(kmeans, k=(2,50))\n",
    "        visualizer.fit(data) \n",
    "        visualizer.poof() \n",
    "        kmeans = KMeans(n_clusters = 4)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        kumeler = k_fit.labels_\n",
    "    def HiyerarsikKume(self,data):\n",
    "        hc_complete = linkage(df, \"complete\")\n",
    "        hc_average = linkage(df, \"average\")\n",
    "        hc_single = linkage(df, \"single\")\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.title('Hiyerarşik Kümeleme - Dendogram')\n",
    "        plt.xlabel('Indexler')\n",
    "        plt.ylabel('Uzaklık')\n",
    "        dendrogram(\n",
    "        hc_complete,\n",
    "        leaf_font_size=10);\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.title('Hiyerarşik Kümeleme - Dendogram')\n",
    "        plt.xlabel('Indexler')\n",
    "        plt.ylabel('Uzaklık')\n",
    "        dendrogram(\n",
    "        hc_complete,\n",
    "        truncate_mode = \"lastp\",\n",
    "        p = 4,\n",
    "        show_contracted = True);\n",
    "    def HiyerarsikOptimumKume (self,data):\n",
    "        cluster = AgglomerativeClustering(n_clusters = 4, \n",
    "                                  affinity = \"euclidean\", \n",
    "                                  linkage = \"ward\")\n",
    "\n",
    "        cluster.fit_predict(data)\n",
    "        data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TÜM MODELLERİN KARŞILAŞTIRILMASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeller = [\n",
    "    knn_tuned,\n",
    "    loj_model,\n",
    "    svc_tuned,\n",
    "    nb_model,\n",
    "    mlpc_tuned,\n",
    "    cart_tuned,\n",
    "    rf_tuned,\n",
    "    gbm_tuned,\n",
    "    catb_tuned,\n",
    "    lgbm_tuned,\n",
    "    xgb_tuned\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)\n",
    "    print(\"-\"*28)\n",
    "    print(isimler + \":\" )\n",
    "    print(\"Accuracy: {:.4%}\".format(dogruluk))\n",
    "    \n",
    "    \n",
    "\n",
    "sonuc = []\n",
    "\n",
    "sonuclar = pd.DataFrame(columns= [\"Modeller\",\"Accuracy\"])\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)    \n",
    "    sonuc = pd.DataFrame([[isimler, dogruluk*100]], columns= [\"Modeller\",\"Accuracy\"])\n",
    "    sonuclar = sonuclar.append(sonuc)\n",
    "    \n",
    "    \n",
    "sns.barplot(x= 'Accuracy', y = 'Modeller', data=sonuclar, color=\"r\")\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Modellerin Doğruluk Oranları');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
